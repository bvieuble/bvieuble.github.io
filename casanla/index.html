<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="NUK2RNw-uH6-2th-7YWdtPJhZGP2V_U11cBTumDXM5Y"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> CAS-ANLA | Bastien Vieublé </title> <meta name="author" content="Bastien Vieublé"> <meta name="description" content="The Chinese Academy of Sciences Workshop on Approximate computing in Numerical Linear Algebra (2025 Edition)."> <meta name="keywords" content="high performance computing, numerical linear algebra, rounding errors, linear systems of equations"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.css" integrity="sha256-uRX+PiRTR4ysKFRCykT8HLuRCub26LgXJZym3Yeom1c=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.font.im/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link defer href="/assets/css/bootstrap-toc.min.css?6f5af0bb9aab25d79b2448143cbeaa88" rel="stylesheet"> <link rel="shortcut icon" href="/assets/img/logo-amss.png?ba163e6a9247158fad73c7c469e3e91c"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://bvieuble.me/casanla/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <link defer rel="stylesheet" href="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.css" integrity="sha256-q9ba7o845pMPFU+zcAll8rv+gC+fSovKsOoNQ6cynuQ=" crossorigin="anonymous"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Bastien</span> Vieublé </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/texfantasy/">TexFantasy </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item active"> <a class="nav-link" href="/casanla/">CAS-ANLA <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="row"> <div class="col-sm-3"> <nav id="toc-sidebar" class="sticky-top"></nav> </div> <div class="col-sm-9"> <div class="post"> <header class="post-header"> <h1 class="post-title">CAS-ANLA</h1> <p class="post-description">The Chinese Academy of Sciences Workshop on Approximate computing in Numerical Linear Algebra (2025 Edition).</p> </header> <article> <article> <style>body{text-align:justify}</style> <p>Linear algebra kernels and algorithms are prevalent in scientific computing, machine learning, statistics, image processing, and much more. With the ever-increasing scale and complexity of some of those computational problems, the need for scalable and cost-effective linear algebra algorithms is critical. For this reason, approximate computing techniques have been increasingly used in modern linear algebra algorithms. These techniques can substantially reduce the algorithms’ complexities by introducing (controlled) errors into the calculations. Those techniques include, but are not limited to, low-rank approximations, mixed precision, randomization, or tensor compression.</p> <p>The Chinese Academy of Sciences Workshop on Approximate Computing in Numerical Linear Algebra (CAS-ANLA) aims to provide greater exposure to the topic of approximate computing techniques to the local Chinese and Asian scientific community. It will gather outstanding researchers and students from China working in approximate computing together with some of the best international experts in the field. The speakers will illustrate theoretically and experimentally the benefit of cutting-edge approximate computing techniques and present recent advances in the field. We also expect other topics to be represented, such as optimization, machine learning, or functions of matrices to name a few.</p> <p>The CAS-ANLA workshop will be spread over two days and will feature <strong>14 plenaries</strong> in which the speakers will develop on their expertise and recent advances on the topic. In total, <strong>13 different institutions</strong> are represented, 6 of them are from abroad, 3 of them are Chinese institutes outside Beijing.</p> <h2 id="how-to-attend">How to attend?</h2> <p>The event will take place in the South building of the Academy of Mathematics and Systems Science in <strong>room N204</strong> (2nd floor) on <strong>April 23rd and 24th, 2025</strong>. Everybody is welcome (and encourage) to attend the talks, meet our speakers, ask questions, and, eventually, start a fruitful collaboration.</p> <h2 id="program-day-1-april-23rd">Program day 1 (April 23rd)</h2> <p><br></p> <table> <thead> <tr> <th style="text-align: center">Time</th> <th style="text-align: left">Speakers</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">8:30 - 8:50</td> <td style="text-align: left">Welcoming</td> </tr> <tr> <td style="text-align: center">8:50 - 9:00</td> <td style="text-align: left">Opening Remarks</td> </tr> <tr> <td style="text-align: center">9:00 - 9:50</td> <td style="text-align: left"><a href="#liu">Weifeng Liu</a></td> </tr> <tr> <td style="text-align: center">9:50 - 10:40</td> <td style="text-align: left"><a href="#sogabe">Tomohiro Sogabe</a></td> </tr> <tr> <td style="text-align: center">10:40 - 11:00</td> <td style="text-align: left">Coffee break</td> </tr> <tr> <td style="text-align: center">11:00 - 11:50</td> <td style="text-align: left"><a href="#yin">Junfeng Yin</a></td> </tr> <tr> <td style="text-align: center">12:00 - 14:00</td> <td style="text-align: left">Lunch break</td> </tr> <tr> <td style="text-align: center">14:00 - 14:50</td> <td style="text-align: left"><a href="#giraud">Luc Giraud</a></td> </tr> <tr> <td style="text-align: center">14:50 - 15:40</td> <td style="text-align: left"><a href="#shao">Meiyue Shao</a></td> </tr> <tr> <td style="text-align: center">15:40 - 16:00</td> <td style="text-align: left">Coffee break</td> </tr> <tr> <td style="text-align: center">16:00 - 16:50</td> <td style="text-align: left"><a href="#czhang">Chensong Zhang</a></td> </tr> <tr> <td style="text-align: center">16:50 - 17:40</td> <td style="text-align: left"><a href="#chen">Xinye Chen</a></td> </tr> </tbody> </table> <p><br></p> <h2 id="program-day-2-april-24th">Program day 2 (April 24th)</h2> <p><br></p> <table> <thead> <tr> <th style="text-align: center">Time</th> <th style="text-align: left">Speakers</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">8:30 - 9:00</td> <td style="text-align: left">Welcoming</td> </tr> <tr> <td style="text-align: center">9:00 - 9:50</td> <td style="text-align: left"><a href="#tisseur">Françoise Tisseur</a></td> </tr> <tr> <td style="text-align: center">9:50 - 10:40</td> <td style="text-align: left"><a href="#zou">Qinmeng Zou</a></td> </tr> <tr> <td style="text-align: center">10:40 - 11:00</td> <td style="text-align: left">Coffee break</td> </tr> <tr> <td style="text-align: center">11:00 - 11:50</td> <td style="text-align: left"><a href="#kopanicakova">Alena Kopanicakova</a></td> </tr> <tr> <td style="text-align: center">12:00 - 14:00</td> <td style="text-align: left">Lunch break</td> </tr> <tr> <td style="text-align: center">14:00 - 14:50</td> <td style="text-align: left"><a href="#zzhang">Zaikun Zhang</a></td> </tr> <tr> <td style="text-align: center">14:50 - 15:40</td> <td style="text-align: left"><a href="#li">Qingna Li</a></td> </tr> <tr> <td style="text-align: center">15:40 - 16:00</td> <td style="text-align: left">Coffee break</td> </tr> <tr> <td style="text-align: center">16:00 - 16:50</td> <td style="text-align: left"><a href="#mikaitis">Mantas Mikaitis</a></td> </tr> <tr> <td style="text-align: center">16:50 - 17:40</td> <td style="text-align: left"><a href="#fasi">Massimiliano Fasi</a></td> </tr> <tr> <td style="text-align: center">17:40 - 17:50</td> <td style="text-align: left">Closing Remarks</td> </tr> </tbody> </table> <p><br></p> <h2 data-toc-text="Speakers" id="list-of-speakers">List of speakers</h2> </article> <div class="post"> <article> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/liu-480.webp 480w,/assets/img//casanla25/liu-800.webp 800w,/assets/img//casanla25/liu-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/liu.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/liu.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="right"><a href="https://www.ssslab.cn/people/weifengliu.html" rel="external nofollow noopener" target="_blank">Weifeng Liu</a></div> <div align="right">China University of Petroleum-Beijing</div> <div align="right">Beijing, China</div> </div> </div> <div class="clearfix"> <h3 id="liu" style="text-align: left;font-size:26px !important;" data-toc-text="Weifeng Liu">Block-Wise Mixed Precision Sparse Solvers</h3> <p>Sparse direct and iterative solvers play a crucial role in scientific computing and engineering applications. Mixed precision computing, which integrates double, single, and half precision arithmetic, provides an effective approach to reducing computational costs while hopefully preserving solution accuracy. This talk will present our two recent advancements in mixed precision-enhanced open-source solvers: the sparse direct solver PanguLU <a href="https://dl.acm.org/doi/10.1145/3581784.3607050" rel="external nofollow noopener" target="_blank">(Fu et al., SC ‘23)</a> and the sparse iterative solver Mille-feuille <a href="https://ieeexplore.ieee.org/abstract/document/10793204" rel="external nofollow noopener" target="_blank">(Yang et al., SC ‘24)</a>. Both solvers employ block-wise mixed precision strategies on GPUs, and exhibit obvious performance improvements over their original FP64-precision counterparts.</p> <p>Link to the articles:</p> <ul> <li><a href="https://dl.acm.org/doi/10.1145/3581784.3607050" rel="external nofollow noopener" target="_blank">PanguLU: A Scalable Regular Two-Dimensional Block-Cyclic Sparse Direct Solver on Distributed Heterogeneous Systems</a></li> <li><a href="https://ieeexplore.ieee.org/abstract/document/10793204" rel="external nofollow noopener" target="_blank">Mille-feuille: A Tile-Grained Mixed Precision Single-Kernel Conjugate Gradient Solver on GPUs</a></li> </ul> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/sogabe-480.webp 480w,/assets/img//casanla25/sogabe-800.webp 800w,/assets/img//casanla25/sogabe-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/sogabe.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/sogabe.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="left"><a href="https://na.nuap.nagoya-u.ac.jp/~sogabe/sogabe_e.html" rel="external nofollow noopener" target="_blank">Tomohiro Sogabe</a></div> <div align="left">Nagoya University</div> <div align="left">Nagoya, Japan</div> </div> </div> <div class="clearfix"> <h3 id="sogabe" style="text-align: right;font-size:26px !important;" data-toc-text="Tomohiro Sogabe">Recent Developments in Krylov Subspace Methods for Nonsymmetric Shifted Linear Systems</h3> <p>Shifted linear systems of the form \((A+ s_{k} I)x_{k}=b\) for \(k=1,2,\dots, n\) frequently arise in quantum chromodynamics and large-scale electronic structure calculations. These linear systems also appear in subproblems of eigenvalue problems and matrix function computations. In this talk, we briefly review Krylov subspace methods for solving nonsymmetric linear systems, along with our recent solver that is joint work with R. Zhao.</p> </div> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/yin-480.webp 480w,/assets/img//casanla25/yin-800.webp 800w,/assets/img//casanla25/yin-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/yin.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/yin.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="right"><a href="https://math.tongji.edu.cn/info/1386/7735.htm" rel="external nofollow noopener" target="_blank">Junfeng Yin</a></div> <div align="right">Tongji University</div> <div align="right">Shanghai, China</div> </div> </div> <div class="clearfix"> <h3 id="yin" style="text-align: left;font-size:26px !important;" data-toc-text="Junfeng Yin">Surrogate hyperplane Bregman–Kaczmarz methods for solving linear inverse problems</h3> <p>Linear inverse problems arise in many practical applications, for instance, compressed sensing, phase retrieval and regularized basis pursuit problem. We propose a residual-based surrogate hyperplane Bregman-Kaczmarz method (RSHBK) for solving this kind of problems. The convergence theory of the proposed method is investigated in details. When the data is contaminated by the independent noise, an adaptive version of our RSHBK method is developed. An adaptive relaxation parameter is derived for optimizing the bound on the expectation error. We demonstrate the efficiency of our proposed methods for both noise-free and independent noise problems by comparing with other state-of-the-art Kaczmarz methods in terms of computation time and convergence rate through synthetic experiments and real-world applications.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/avatar-480.webp 480w,/assets/img//casanla25/avatar-800.webp 800w,/assets/img//casanla25/avatar-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/avatar.png" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/avatar.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="left"><a href="https://scholar.google.com/citations?user=NIbqWDEAAAAJ&amp;hl=fr" rel="external nofollow noopener" target="_blank">Luc Giraud</a></div> <div align="left">INRIA</div> <div align="left">Bordeaux, France</div> </div> </div> <div class="clearfix"> <h3 id="giraud" style="text-align: right;font-size:26px !important;" data-toc-text="Luc Giraud">A journey through some numerical linear algebra algorithms with variable accuracy <div style="font-size:12px !important;">joint work with E. Agullo, O. Coulaud, M. Iannacito. M. Issa, G. Marait, M. Rozloznik</div> </h3> <p>In this talk, we will explore the numerical behavior of widely used numerical linear algebra methods when the errors introduced by the underlying hardware and working arithmetic are decoupled from those associated with the data representation of mathematical objects—primarily matrices and vectors—computed by the algorithms, a concept we refer to as variable accuracy.</p> <p>We will present experimental results in fundamental contexts, including basis orthogonalization using Modified Gram-Schmidt variants, the solution of linear systems with GMRES, and eigenproblem solutions via the FEAST method.</p> <p>Additionally, we will discuss the numerical quality of the computed results under variable accuracy and draw connections with well-established results in finite precision arithmetic.</p> <p>Finally, we will showcase applications in low-rank tensor computations using the Tensor Train format, along with ongoing perturbation analysis to justify the observed experimental behavior.</p> <leftmouse> </leftmouse> </div> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/shao-480.webp 480w,/assets/img//casanla25/shao-800.webp 800w,/assets/img//casanla25/shao-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/shao.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/shao.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="right"><a href="https://scholar.google.com/citations?user=yk0MnRQAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Meiyue Shao</a></div> <div align="right">Fudan University</div> <div align="right">Shanghai, China</div> </div> </div> <div class="clearfix"> <h3 id="shao" style="text-align: left;font-size:26px !important;" data-toc-text="Meiyue Shao">Exploiting low-precision arithmetic in eigensolvers</h3> <p>In recent years mixed-precision algorithms have received increasing attention in numerical linear algebra and high performance computing. Modern mixed-precision algorithms perform a significant amount of low-precision arithmetic in order to speed up the computation, while still providing the desired solution in working precision. A number of existing works in the literature focus on mixed-precision linear solvers—much less is known about how to improve eigensolvers. In this talk we discuss several techniques that can accelerate eigenvalue computations by exploiting low-precision arithmetic. These techniques lead to several mixed-precision symmetric eigensolvers, for both dense and sparse eigenvalue problems. Our mixed-precision algorithms outperform existing fixed-precision algorithms without compromising the accuracy of the final solution.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/czhang-480.webp 480w,/assets/img//casanla25/czhang-800.webp 800w,/assets/img//casanla25/czhang-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/czhang.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/czhang.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="left"><a href="https://lsec.cc.ac.cn/~zhangcs/" rel="external nofollow noopener" target="_blank">Chensong Zhang</a></div> <div align="left">LSEC, AMSS, Chinese Academy of Sciences</div> <div align="left">Beijing, China</div> </div> </div> <div class="clearfix"> <h3 id="czhang" style="text-align: right;font-size:26px !important;" data-toc-text="Chensong Zhang">Learning-based Multilevel Solvers for Large-Scale Linear Systems</h3> <p>This talk presents our efforts on developing learning-based solvers for large-scale linear systems arising from discretized PDEs. Our approach bridges traditional multilevel solvers with machine learning, automating solver design to enhance efficiency and scalability. The method generalizes across grid sizes, coefficients, and right-hand-side terms, enabling offline training and efficient generalization, with convolutional neural networks (CNNs) serving as the basic computational kernels. It utilizes multilevel hierarchy for rapid convergence and cross-level weight sharing to adapt flexibly to varying grid sizes. The proposed solver achieves speedup over classical geometric multigrid methods for convection-diffusion PDEs in preliminary numerical experiments. We further extend this framework by introducing a Fourier neural network (FNN) to accelerate source influence propagation in Helmholtz equations within heterogeneous media. Supervised experiments demonstrate superior accuracy and efficiency compared to other neural operators, while unsupervised scalability tests reveal significant speedups over other AI solvers, achieving near-optimal convergence for wave numbers up to \(k \approx 2000\). Ablation studies validate the effectiveness of the multigrid hierarchy and the novel FNN architecture.</p> </div> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/chen-480.webp 480w,/assets/img//casanla25/chen-800.webp 800w,/assets/img//casanla25/chen-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/chen.png" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/chen.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="right"><a href="https://xinyechen.com/" rel="external nofollow noopener" target="_blank">Xinye Chen</a></div> <div align="right">Sorbonne University</div> <div align="right">Paris, France</div> </div> </div> <div class="clearfix"> <h3 id="chen" style="text-align: left;font-size:26px !important;" data-toc-text="Xinye Chen">Mixed-precision HODLR matrices</h3> <p>Hierarchical matrix computations have attracted significant attention in the science and engineering community as exploiting data-sparse structures can significantly reduce the computational complexity of many important kernels. One particularly popular option within this class is the Hierarchical Off-Diagonal Low-Rank (HODLR) format. This talk demonstrates that off-diagonal low-rank blocks in HODLR matrices can be stored in reduced precision without degrading overall accuracy. An adaptive-precision scheme ensures numerical stability in key computations. We provide theoretical insights to guide precision selection, with experiments confirming effectiveness. An emulation software that facilitates the research on HODLR matrix computations is also presented.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/tisseur-480.webp 480w,/assets/img//casanla25/tisseur-800.webp 800w,/assets/img//casanla25/tisseur-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/tisseur.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/tisseur.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="left"><a href="https://personal.maths.manchester.ac.uk/tisseur/" rel="external nofollow noopener" target="_blank">Françoise Tisseur</a></div> <div align="left">The University of Manchester</div> <div align="left">Manchester, UK</div> </div> </div> <div class="clearfix"> <h3 id="tisseur" style="text-align: right;font-size:26px !important;" data-toc-text="Françoise Tisseur">Computing accurate eigenvalues using a mixed-precision Jacobi algorithm <div style="font-size:12px !important;">joint work with N. J. Higham, M. Webb, and Z. Zhou</div> </h3> <p>Efforts on developing mixed precision algorithms in the numerical linear algebra and high performance computing communities have mainly focussed on linear systems and least squares problems. Eigenvalue problems are considerably more challenging to solve and have a larger solution space that cannot be computed in a finite number of steps</p> <p>In this talk we present a mixed-precision preconditioned Jacobi algorithm, which uses low precision to compute the preconditioner, applies it in high precision (amounting to two matrix-matrix multiplications) and solves the eigenproblem using the Jacobi algorithm in working precision. Our analysis yields meaningfully smaller relative forward error bounds for the computed eigenvalues compared with those of the standard Jacobi algorithm. We further prove that, after preconditioning, if the off-diagonal entries of the preconditioned matrix are sufficiently small relative to its smallest diagonal entry, the relative forward error bound is independent of the condition number of the original matrix. We present two constructions for the preconditioner that exploit low precision, along with their error analyses. Our numerical experiments confirm our theoretical results.</p> </div> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/zou-480.webp 480w,/assets/img//casanla25/zou-800.webp 800w,/assets/img//casanla25/zou-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/zou.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/zou.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="right"><a href="https://sites.google.com/view/zouqinmeng/" rel="external nofollow noopener" target="_blank">Qinmeng Zou</a></div> <div align="right">Beijing University of Posts and Telecommunications</div> <div align="right">Beijing, China</div> </div> </div> <div class="clearfix"> <h3 id="zou" style="text-align: left;font-size:26px !important;" data-toc-text="Qinmeng Zou">Stability of modified Gram-Schmidt and its low-synchronization variants</h3> <p>Modified Gram-Schmidt (MGS) is a traditional QR factorization process that are widely used in solving linear systems and least squares problems. For example, the generalized minimal residual method (GMRES) usually employs QR factorization to orthogonalize the basis of Krylov subspace. This talk discusses a class of low-synchronization MGS algorithms, denoted as MGS-LTS, which can date back to Bjorck’s work in 1967. We give a stability analysis of MGS-LTS, proving that the loss of orthogonality of its basic form as well as the block and normalization lagging variants is proportional to the condition number. We also discuss the probabilistic tools and investigate the causes of instability of the Cholesky-based block variant. Finally, we show numerical experiments for the mixed-precision low-synchronization GMRES algorithm with sparse approximate inverse preconditioning.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/avatar-480.webp 480w,/assets/img//casanla25/avatar-800.webp 800w,/assets/img//casanla25/avatar-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/avatar.png" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/avatar.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="left"><a href="https://kopanicakova.github.io/" rel="external nofollow noopener" target="_blank">Alena Kopanicakova</a></div> <div align="left">INPT/ENSEEIHT, ANITI</div> <div align="left">Toulouse, France</div> </div> </div> <div class="clearfix"> <h3 id="kopanicakova" style="text-align: right;font-size:26px !important;" data-toc-text="Alena Kopanicakova">Towards trustworthy use of scientific machine-learning in large scale numerical simulations</h3> <p>Recently, scientific machine learning (SciML) has expanded the capabilities of traditional numerical approaches by simplifying computational modeling and providing cost-effective surrogates. However, SciML models suffer from the absence of explicit error control, a computationally intensive training phase, and a lack of reliability in practice. In this talk, we will take the first steps toward addressing these challenges by exploring two different research directions. Firstly, we will demonstrate how the use of advanced numerical methods, such as multilevel and domain-decomposition solution strategies, can contribute to efficient training and produce more accurate SciML models. Secondly, we propose to hybridize SciML models with state-of-the-art numerical solution strategies. This approach will allow us to take advantage of the accuracy and reliability of standard numerical methods while harnessing the efficiency of SciML. The effectiveness of the proposed training and hybridization strategies will be demonstrated by means of several numerical experiments, encompassing the training of DeepONets and the solving of linear systems of equations that arise from the high-fidelity discretization of linear parametric PDEs using DeepONet-enhanced multilevel and domain-decomposition methods.</p> </div> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/zzhang-480.webp 480w,/assets/img//casanla25/zzhang-800.webp 800w,/assets/img//casanla25/zzhang-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/zzhang.png" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/zzhang.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="right"><a href="https://www.zhangzk.net/" rel="external nofollow noopener" target="_blank">Zaikun Zhang</a></div> <div align="right">Sun Yat-sen University</div> <div align="right">Guangzhou, China</div> </div> </div> <div class="clearfix"> <h3 id="zzhang" style="text-align: left;font-size:26px !important;" data-toc-text="Zaikun Zhang">Solving 10,000-Dimensional Optimization Problems Using Inaccurate Function Values: An Old Algorithm</h3> <p>We reintroduce a derivative-free subspace optimization framework originating from Chapter 5 of [Z. Zhang, On Derivative-Free Optimization Methods, PhD thesis, Chinese Academy of Sciences, Beijing, 2012 (supervisor Ya-xiang Yuan)]. At each iteration, the framework defines a low-dimensional subspace based on an approximate gradient, and then solves a subproblem in this subspace to generate a new iterate. We sketch the global convergence and worst-case complexity analysis of the framework, elaborate on its implementation, and present some numerical results on problems with dimensions as high as 10,000.</p> <p>The same framework was presented by Zhang during ICCOPT 2013 in Lisbon under the title “A Derivative-Free Optimization Algorithm with Low-Dimensional Subspace Techniques for Large-Scale Problems”, although it remained nearly unknown to the community until very recently. An algorithm following this framework named NEWUOAs was implemented by Zhang in MATLAB in 2011 (<a href="https://github.com/newuoas/newuoas" rel="external nofollow noopener" target="_blank">link to code</a>), ported to Modula-3 in 2016 by M. Nystroem, a Principal Engineer at the Intel Corporation, and made available in the open-source package CM3 (<a href="https://github.com/modula3/cm3/blob/master/caltech-other/newuoa/src/NewUOAs.m3" rel="external nofollow noopener" target="_blank">link to package</a>). NEWUOAs has been used by Intel in the design of chips, including its flagship product Atom P5900.</p> <p>More information about the framework can be found in the paper: <a href="https://arxiv.org/abs/2501.04536" rel="external nofollow noopener" target="_blank">Scalable Derivative-Free Optimization Algorithms With Low-Dimensional Subspace Techniques</a>.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/li-480.webp 480w,/assets/img//casanla25/li-800.webp 800w,/assets/img//casanla25/li-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/li.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/li.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="left"><a href="https://pure.bit.edu.cn/en/persons/qingna-li" rel="external nofollow noopener" target="_blank">Qingna Li</a></div> <div align="left">Beijing Institute of Technology</div> <div align="left">Beijing, China</div> </div> </div> <div class="clearfix"> <h3 id="li" style="text-align: right;font-size:26px !important;" data-toc-text="Qingna Li">A Fast BB Reduced Minimization Algorithm for Nonnegative Viscosity Optimization in Optimal Damping</h3> <p>We consider the fast optimization algorithm for optimal viscosities in damping system. Different from standard models that minimize the trace of the solution of parameterized Lyapunov equation, the nonnegative constraints for viscosities are added in the optimization model, which hasn’t been considered before. To solve the new model, an efficient algorithm is then proposed, aiming at reducing the residuals of the corresponding KKT conditions. By combining with the Barzilai-Borwein stepsize, the proposed BB residual minimization algorithm (short for BBRMA) can further speed up to deal with large scale linear vibration systems. Extensive numerical results verify the high efficiency of the proposed algorithm. This is the joint work with Françoise Tisseur.</p> </div> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/mikaitis-480.webp 480w,/assets/img//casanla25/mikaitis-800.webp 800w,/assets/img//casanla25/mikaitis-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/mikaitis.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/mikaitis.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="right"><a href="https://mmikaitis.github.io/" rel="external nofollow noopener" target="_blank">Mantas Mikaitis</a></div> <div align="right">University of Leeds</div> <div align="right">Leeds, UK</div> </div> </div> <div class="clearfix"> <h3 id="mikaitis" style="text-align: left;font-size:26px !important;" data-toc-text="Mantas Mikaitis">Error Analysis of Matrix Multiplication with Narrow Range Floating-Point Arithmetic <div style="font-size:12px !important;">joint work with T. Mary</div> </h3> <p>High-performance computing hardware now supports many different floating-point formats, from 64 bits to only 4 bits. While the effects of reducing precision in numerical linear algebra computations have been extensively studied, some of these low precision formats also possess a very narrow range of representable values, meaning underflow and overflow are very likely. The goal of this article is to analyze the consequences of this narrow range on the accuracy of matrix multiplication. We describe a simple scaling that can prevent overflow while minimizing underflow. We carry out an error analysis to bound the underflow errors and show that they should remain dominated by the rounding errors in most practical scenarios. We also show that this conclusion remains true when multiword arithmetic is used. We perform extensive numerical experiments that confirm that the narrow range of low precision arithmetics should not significantly affect the accuracy of matrix multiplication—provided a suitable scaling is used.</p> <p>Link to the article: <a href="https://hal.science/hal-04671474v2/document" rel="external nofollow noopener" target="_blank">Error analysis of matrix multiplication with narrow range floating-point arithmetic</a>.</p> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img//casanla25/fasi-480.webp 480w,/assets/img//casanla25/fasi-800.webp 800w,/assets/img//casanla25/fasi-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img//casanla25/fasi.jpg" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="/casanla25/fasi.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <div align="left"><a href="https://eps.leeds.ac.uk/computing/staff/14034/massimiliano-fasi" rel="external nofollow noopener" target="_blank">Massimiliano Fasi</a></div> <div align="left">University of Leeds</div> <div align="left">Leeds, UK</div> </div> </div> <div class="clearfix"> <h3 id="fasi" style="text-align: right;font-size:26px !important;" data-toc-text="Massimiliano Fasi">Analysis of Floating-Point Matrix Products Computed via Low-Precision Integer Arithmetic</h3> <p>Matrix multiplication is arguably a fundamental kernel in scientific computing, and efficient implementations underpin the performance of many numerical algorithms for linear algebra. The Ozaki scheme is a method that computes matrix–matrix products by recasting them as sequences of error-free transformations. First developed in 2008 in the context of summation, this technique has recently seen a resurgence of interest, because it is particularly well suited to the mixed-precision matrix-multiplication units available on modern hardware accelerators (such as GPUs, TPUs, or NPUs). The latest generations of these accelerators are particularly efficient at computing products between matrices of low-precision integers. In scientific application, integers are typically not sufficient, but, in the last couple of years, variants of the Ozaki scheme that rewrite <em>floating-point</em> matrix multiplications in terms of <em>integer</em> matrix products have been proposed. We analyse the error incurred by these integer variants of the Ozaki scheme, and we characterise cases in which these methods can fail.</p> </div> <hr> <div class="profile float-left"> </div> <div class="clearfix"> <h2 id="poster">Poster</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/casanla25/poster-480.webp 480w,/assets/img/casanla25/poster-800.webp 800w,/assets/img/casanla25/poster-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/casanla25/poster.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="how-to-come">How to come?</h2> <p>地址: 北京市海淀区中关村东路55号 邮政编码：100190.</p> <p>Address: China Academy of Sciences Fundamental Science Park, No.55, Zhongguancun East Road, Haidian Beijing China, 100190.</p> <p>Closest subway station: Zhichunlu (line 10).</p> <pre><code class="language-geojson">{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {},
      "geometry": {
        "coordinates": [
          116.3259971722868,
          39.98092190406621
        ],
        "type": "Point"
      }
    }
  ]
}
</code></pre> <p><br></p> <h2 id="our-sponsors">Our sponsors</h2> <ul> <li>Academy of Mathematics and Systems Science, Chinese Academy of Sciences</li> <li>CAS AMSS-PolyU Joint Laboratory of Applied Mathematics</li> <li>National Key R&amp;D Program of China</li> <li>National Natural Science Foundation of China</li> <li>State Key Laboratory of Mathematical Sciences, AMSS, CAS</li> </ul> </div> </article> </div> </article> </div> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Bastien Vieublé. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script src="https://cdn.jsdelivr.net/npm/leaflet@1.9.4/dist/leaflet.min.js" integrity="sha256-MgH13bFTTNqsnuEoqNPBLDaqxjGH+lCpqrukmXc8Ppg=" crossorigin="anonymous"></script> <script defer src="/assets/js/leaflet-setup.js?f0b030b275b8e13cb43e42ac1749df31" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script defer src="/assets/js/bootstrap-toc.min.js?c82ff4de8b0955d6ff14f5b05eed7eb6"></script> <script defer src="https://cdn.jsdelivr.net/npm/bootstrap-table@1.22.4/dist/bootstrap-table.min.js" integrity="sha256-4rppopQE9POKfukn2kEvhJ9Um25Cf6+IDVkARD0xh78=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>